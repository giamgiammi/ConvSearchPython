<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>convSearchPython.pipelines.sub_index API documentation</title>
<meta name="description" content="This module contains a collection of pipelines that
for every conversation: …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>convSearchPython.pipelines.sub_index</code></h1>
</header>
<section id="section-intro">
<p>This module contains a collection of pipelines that
for every conversation:</p>
<ul>
<li>create a temporary index based on the result for the 1° utterance</li>
<li>search for subsequent utterance inside the temporary index</li>
</ul>
<p>The idea is that the first utterance will likely contain the
main argument of the conversation and so its search results likely
will contain the relevant documents for the entire conversation.
This is similar to the filter used in <code>pipelines.filtered</code>, but
starting from the last utterance and going up.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module contains a collection of pipelines that
for every conversation:

- create a temporary index based on the result for the 1° utterance
- search for subsequent utterance inside the temporary index

The idea is that the first utterance will likely contain the
main argument of the conversation and so its search results likely
will contain the relevant documents for the entire conversation.
This is similar to the filter used in `pipelines.filtered`, but
starting from the last utterance and going up.
&#34;&#34;&#34;
import inspect
from typing import Type, Dict, Tuple, List

from convSearchPython.pipelines import *
from convSearchPython.searching.sub_index import sub_index_search
from convSearchPython.utils.data_utils import queries_conversation_splitter
from convSearchPython.utils.imports import import_pipeline
from convSearchPython.utils.parallel_utils import RunPipeline


class SubIndexPipeline(AbstractWrapperPipelineInterface):
    &#34;&#34;&#34;
    Pipeline with sub index

    These pipelines execute a search on the first utterance of the conversation,
    the use the results to build a temp index to execute the following ones.

    -----
    ## Important Note:
    Pipeline that use RM3 will fail unless you set the environment variable
    &#34;SUB_INDEX_DIR&#34; with a path of an actual dir where the temp index will
    be created. To keep everything in ram you can use a path inside /dev/shm
    &#34;&#34;&#34;

    def __init__(self, index: Index, queries: pd.DataFrame, conversations: Dict[str, List[str]],
                 query_map: Dict[str, Tuple[str, int]], metadata: RetrieveMetadata, sub_pipeline: str,
                 mu=2500, c=0.75, rm3=False, fb_terms=20, fb_docs=20, fb_lambda=0.5,
                 index_base_results=10000, rerun_first=False,
                 bm25_on_first=False, sub_apply_rm3=False,
                 sub_fb_terms=None, sub_fb_docs=None, sub_fb_lambda=None, **kwargs):
        &#34;&#34;&#34;
        Args:
            sub_pipeline: reference name for a class extending
            `convSearchPython.pipelines.AbstractPipeline` that will be used for sub search
            on utterance after the first
            index: index to use (enum)
            queries: queries DataFrame
            conversations: conversation map
            query_map: query map
            metadata: metadata to retrieve
            index_base_results: results for the base phase (will be used as docs in the temp index)
            rerun_first: rerun the first utterance in the temp index
            bm25_on_first: use BM25 on the base run instead of Dirichlet
            mu: mu parameter of dirichlet language model
            c: BM25 parameter
            rm3: if to apply RM3
            fb_terms: RM3 term number for base search
            fb_docs: RM3 number of docs for base search
            fb_lambda: RM3 lambda for base search
            sub_apply_rm3: apply RM3 to the sub search
            sub_fb_terms: RM3 terms number for sub search
            sub_fb_docs: RM3 docs number for sub search
            sub_fb_lambda: RM3 lambda for sub search
            **kwargs: extra parameters to pass to rewriting_pipeline during creation
        &#34;&#34;&#34;
        self._index_base_results = index_base_results
        self._rerun_first = rerun_first
        self._bm25_on_first = bm25_on_first
        self._c = c
        self._sub_fb_terms = sub_fb_terms
        self._sub_fb_docs = sub_fb_docs
        self._sub_fb_lambda = sub_fb_lambda
        self._sub_apply_rm3 = sub_apply_rm3
        self._index = index
        self._metadata = metadata
        self._fb_terms = fb_terms
        self._fb_docs = fb_docs
        self._fb_lambda = fb_lambda
        self._apply_rm3 = rm3
        self._mu = mu
        self._queries = queries
        self._conversations = conversations
        self._query_map = query_map

        self._query_map = query_map
        self._conversations = conversations
        cls: Type[AbstractPipeline] = import_pipeline(sub_pipeline)
        if issubclass(cls, QueriesStructNeedingInterface):
            kwargs[&#39;queries&#39;] = queries
            kwargs[&#39;conversations&#39;] = conversations
            kwargs[&#39;query_map&#39;] = query_map
        if not issubclass(cls, CachedPipelineInterface):
            kwargs.pop(&#39;cache_dir&#39;)
        params = {**kwargs, &#39;index&#39;: index, &#39;metadata&#39;: metadata}
        if sub_apply_rm3:
            params.update({
                &#39;rm3&#39;: True,
                &#39;fb_terms&#39;: sub_fb_terms,
                &#39;fb_docs&#39;: sub_fb_docs,
                &#39;fb_lambda&#39;: sub_fb_lambda
            })
        sig = inspect.signature(cls.__init__).parameters
        if &#39;c&#39; in sig:
            params[&#39;c&#39;] = c
        if &#39;mu&#39; in sig:
            params[&#39;mu&#39;] = mu
        if &#39;autosave_cache&#39; in sig:
            params[&#39;autosave_cache&#39;] = False
        self._sub_cls = cls
        self._sub_params = params
        self._wrapped_pipeline = cls(**params)

    @property
    def name(self):
        model = &#39;DLM&#39; if not self._bm25_on_first else &#39;BM25&#39;
        prf = &#39;none&#39;
        if self._apply_rm3:
            prf = f&#39;rm3-{self._fb_terms}-{self._fb_docs}-{self._fb_lambda}&#39;
        rrf = &#39;rerunFirst&#39; if self._rerun_first else &#39;normal&#39;
        return f&#39;SubIndex-{rrf}-{model}-{prf}_{self._wrapped_pipeline.name}&#39;

    def _base(self, num, meta):
        &#34;&#34;&#34;BatchRetrieve for the base phase&#34;&#34;&#34;
        if self._bm25_on_first:
            model = pt.BatchRetrieve(self._index.get_index(),
                                     wmodel=&#34;BM25&#34;,
                                     controls={&#39;c&#39;: self._c},
                                     properties=self._index.get_properties(),
                                     metadata=meta,
                                     num_results=num)
        else:
            model = pt.BatchRetrieve(self._index.get_index(),
                                     wmodel=&#34;DirichletLM&#34;,
                                     controls={&#39;c&#39;: self._mu},  # mu
                                     properties=self._index.get_properties(),
                                     metadata=meta,
                                     num_results=num)
        if self._apply_rm3:
            rm3 = pt.rewrite.RM3(self._index.get_index(),
                                 fb_terms=self._fb_terms,
                                 fb_docs=self._fb_docs,
                                 fb_lambda=self._fb_lambda)
            return model &gt;&gt; rm3 &gt;&gt; model &gt;&gt; pt.rewrite.reset()
        return model

    def _sub(self, index) -&gt; AbstractPipeline:
        &#34;&#34;&#34;Return the pipeline for the sub phase&#34;&#34;&#34;
        params = {**self._sub_params}
        params.update({
            &#39;index&#39;: CustomIndex(index, self._index.get_properties()),
            &#39;metadata&#39;: self._metadata,
        })
        return self._sub_cls(**params)

    def _partial(self, conv):
        return sub_index_search(
            conv_queries=conv,
            base_transformer_factory=self._base,
            sub_transformer_factory=self._sub,
            index_properties=self._index.get_properties(),
            sub_index_size=self._index_base_results,
            num_docs=1000,
            metadata=self._metadata,
            return_tuple_of_ds=True,
            rerun_first_query=False,
        )

    def run_on(self, queries: pd.DataFrame, parallel_pool: Optional[Pool] = None) -&gt; pd.DataFrame:
        conv_queries = queries_conversation_splitter(queries, self._conversations)
        parts = []
        if parallel_pool is None:
            for conv in conv_queries:
                parts.extend(self._partial(conv))
        else:
            res = parallel_pool.imap(RunPipeline(self, &#39;_partial&#39;), conv_queries)
            for r in res:
                parts.extend(r)
        results = pd.concat(parts)

        return results</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="convSearchPython.pipelines.sub_index.SubIndexPipeline"><code class="flex name class">
<span>class <span class="ident">SubIndexPipeline</span></span>
<span>(</span><span>index: <a title="convSearchPython.pipelines.Index" href="index.html#convSearchPython.pipelines.Index">Index</a>, queries: pandas.core.frame.DataFrame, conversations: Dict[str, List[str]], query_map: Dict[str, Tuple[str, int]], metadata: <a title="convSearchPython.pipelines.RetrieveMetadata" href="index.html#convSearchPython.pipelines.RetrieveMetadata">RetrieveMetadata</a>, sub_pipeline: str, mu=2500, c=0.75, rm3=False, fb_terms=20, fb_docs=20, fb_lambda=0.5, index_base_results=10000, rerun_first=False, bm25_on_first=False, sub_apply_rm3=False, sub_fb_terms=None, sub_fb_docs=None, sub_fb_lambda=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Pipeline with sub index</p>
<p>These pipelines execute a search on the first utterance of the conversation,
the use the results to build a temp index to execute the following ones.</p>
<hr>
<h2 id="important-note">Important Note:</h2>
<p>Pipeline that use RM3 will fail unless you set the environment variable
"SUB_INDEX_DIR" with a path of an actual dir where the temp index will
be created. To keep everything in ram you can use a path inside /dev/shm</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sub_pipeline</code></strong></dt>
<dd>reference name for a class extending</dd>
<dt><code><a title="convSearchPython.pipelines.AbstractPipeline" href="index.html#convSearchPython.pipelines.AbstractPipeline">AbstractPipeline</a></code> that will be used for sub search</dt>
<dt>on utterance after the first</dt>
<dt><strong><code>index</code></strong></dt>
<dd>index to use (enum)</dd>
<dt><strong><code>queries</code></strong></dt>
<dd>queries DataFrame</dd>
<dt><strong><code>conversations</code></strong></dt>
<dd>conversation map</dd>
<dt><strong><code>query_map</code></strong></dt>
<dd>query map</dd>
<dt><strong><code>metadata</code></strong></dt>
<dd>metadata to retrieve</dd>
<dt><strong><code>index_base_results</code></strong></dt>
<dd>results for the base phase (will be used as docs in the temp index)</dd>
<dt><strong><code>rerun_first</code></strong></dt>
<dd>rerun the first utterance in the temp index</dd>
<dt><strong><code>bm25_on_first</code></strong></dt>
<dd>use BM25 on the base run instead of Dirichlet</dd>
<dt><strong><code>mu</code></strong></dt>
<dd>mu parameter of dirichlet language model</dd>
<dt><strong><code>c</code></strong></dt>
<dd>BM25 parameter</dd>
<dt><strong><code>rm3</code></strong></dt>
<dd>if to apply RM3</dd>
<dt><strong><code>fb_terms</code></strong></dt>
<dd>RM3 term number for base search</dd>
<dt><strong><code>fb_docs</code></strong></dt>
<dd>RM3 number of docs for base search</dd>
<dt><strong><code>fb_lambda</code></strong></dt>
<dd>RM3 lambda for base search</dd>
<dt><strong><code>sub_apply_rm3</code></strong></dt>
<dd>apply RM3 to the sub search</dd>
<dt><strong><code>sub_fb_terms</code></strong></dt>
<dd>RM3 terms number for sub search</dd>
<dt><strong><code>sub_fb_docs</code></strong></dt>
<dd>RM3 docs number for sub search</dd>
<dt><strong><code>sub_fb_lambda</code></strong></dt>
<dd>RM3 lambda for sub search</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>extra parameters to pass to rewriting_pipeline during creation</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SubIndexPipeline(AbstractWrapperPipelineInterface):
    &#34;&#34;&#34;
    Pipeline with sub index

    These pipelines execute a search on the first utterance of the conversation,
    the use the results to build a temp index to execute the following ones.

    -----
    ## Important Note:
    Pipeline that use RM3 will fail unless you set the environment variable
    &#34;SUB_INDEX_DIR&#34; with a path of an actual dir where the temp index will
    be created. To keep everything in ram you can use a path inside /dev/shm
    &#34;&#34;&#34;

    def __init__(self, index: Index, queries: pd.DataFrame, conversations: Dict[str, List[str]],
                 query_map: Dict[str, Tuple[str, int]], metadata: RetrieveMetadata, sub_pipeline: str,
                 mu=2500, c=0.75, rm3=False, fb_terms=20, fb_docs=20, fb_lambda=0.5,
                 index_base_results=10000, rerun_first=False,
                 bm25_on_first=False, sub_apply_rm3=False,
                 sub_fb_terms=None, sub_fb_docs=None, sub_fb_lambda=None, **kwargs):
        &#34;&#34;&#34;
        Args:
            sub_pipeline: reference name for a class extending
            `convSearchPython.pipelines.AbstractPipeline` that will be used for sub search
            on utterance after the first
            index: index to use (enum)
            queries: queries DataFrame
            conversations: conversation map
            query_map: query map
            metadata: metadata to retrieve
            index_base_results: results for the base phase (will be used as docs in the temp index)
            rerun_first: rerun the first utterance in the temp index
            bm25_on_first: use BM25 on the base run instead of Dirichlet
            mu: mu parameter of dirichlet language model
            c: BM25 parameter
            rm3: if to apply RM3
            fb_terms: RM3 term number for base search
            fb_docs: RM3 number of docs for base search
            fb_lambda: RM3 lambda for base search
            sub_apply_rm3: apply RM3 to the sub search
            sub_fb_terms: RM3 terms number for sub search
            sub_fb_docs: RM3 docs number for sub search
            sub_fb_lambda: RM3 lambda for sub search
            **kwargs: extra parameters to pass to rewriting_pipeline during creation
        &#34;&#34;&#34;
        self._index_base_results = index_base_results
        self._rerun_first = rerun_first
        self._bm25_on_first = bm25_on_first
        self._c = c
        self._sub_fb_terms = sub_fb_terms
        self._sub_fb_docs = sub_fb_docs
        self._sub_fb_lambda = sub_fb_lambda
        self._sub_apply_rm3 = sub_apply_rm3
        self._index = index
        self._metadata = metadata
        self._fb_terms = fb_terms
        self._fb_docs = fb_docs
        self._fb_lambda = fb_lambda
        self._apply_rm3 = rm3
        self._mu = mu
        self._queries = queries
        self._conversations = conversations
        self._query_map = query_map

        self._query_map = query_map
        self._conversations = conversations
        cls: Type[AbstractPipeline] = import_pipeline(sub_pipeline)
        if issubclass(cls, QueriesStructNeedingInterface):
            kwargs[&#39;queries&#39;] = queries
            kwargs[&#39;conversations&#39;] = conversations
            kwargs[&#39;query_map&#39;] = query_map
        if not issubclass(cls, CachedPipelineInterface):
            kwargs.pop(&#39;cache_dir&#39;)
        params = {**kwargs, &#39;index&#39;: index, &#39;metadata&#39;: metadata}
        if sub_apply_rm3:
            params.update({
                &#39;rm3&#39;: True,
                &#39;fb_terms&#39;: sub_fb_terms,
                &#39;fb_docs&#39;: sub_fb_docs,
                &#39;fb_lambda&#39;: sub_fb_lambda
            })
        sig = inspect.signature(cls.__init__).parameters
        if &#39;c&#39; in sig:
            params[&#39;c&#39;] = c
        if &#39;mu&#39; in sig:
            params[&#39;mu&#39;] = mu
        if &#39;autosave_cache&#39; in sig:
            params[&#39;autosave_cache&#39;] = False
        self._sub_cls = cls
        self._sub_params = params
        self._wrapped_pipeline = cls(**params)

    @property
    def name(self):
        model = &#39;DLM&#39; if not self._bm25_on_first else &#39;BM25&#39;
        prf = &#39;none&#39;
        if self._apply_rm3:
            prf = f&#39;rm3-{self._fb_terms}-{self._fb_docs}-{self._fb_lambda}&#39;
        rrf = &#39;rerunFirst&#39; if self._rerun_first else &#39;normal&#39;
        return f&#39;SubIndex-{rrf}-{model}-{prf}_{self._wrapped_pipeline.name}&#39;

    def _base(self, num, meta):
        &#34;&#34;&#34;BatchRetrieve for the base phase&#34;&#34;&#34;
        if self._bm25_on_first:
            model = pt.BatchRetrieve(self._index.get_index(),
                                     wmodel=&#34;BM25&#34;,
                                     controls={&#39;c&#39;: self._c},
                                     properties=self._index.get_properties(),
                                     metadata=meta,
                                     num_results=num)
        else:
            model = pt.BatchRetrieve(self._index.get_index(),
                                     wmodel=&#34;DirichletLM&#34;,
                                     controls={&#39;c&#39;: self._mu},  # mu
                                     properties=self._index.get_properties(),
                                     metadata=meta,
                                     num_results=num)
        if self._apply_rm3:
            rm3 = pt.rewrite.RM3(self._index.get_index(),
                                 fb_terms=self._fb_terms,
                                 fb_docs=self._fb_docs,
                                 fb_lambda=self._fb_lambda)
            return model &gt;&gt; rm3 &gt;&gt; model &gt;&gt; pt.rewrite.reset()
        return model

    def _sub(self, index) -&gt; AbstractPipeline:
        &#34;&#34;&#34;Return the pipeline for the sub phase&#34;&#34;&#34;
        params = {**self._sub_params}
        params.update({
            &#39;index&#39;: CustomIndex(index, self._index.get_properties()),
            &#39;metadata&#39;: self._metadata,
        })
        return self._sub_cls(**params)

    def _partial(self, conv):
        return sub_index_search(
            conv_queries=conv,
            base_transformer_factory=self._base,
            sub_transformer_factory=self._sub,
            index_properties=self._index.get_properties(),
            sub_index_size=self._index_base_results,
            num_docs=1000,
            metadata=self._metadata,
            return_tuple_of_ds=True,
            rerun_first_query=False,
        )

    def run_on(self, queries: pd.DataFrame, parallel_pool: Optional[Pool] = None) -&gt; pd.DataFrame:
        conv_queries = queries_conversation_splitter(queries, self._conversations)
        parts = []
        if parallel_pool is None:
            for conv in conv_queries:
                parts.extend(self._partial(conv))
        else:
            res = parallel_pool.imap(RunPipeline(self, &#39;_partial&#39;), conv_queries)
            for r in res:
                parts.extend(r)
        results = pd.concat(parts)

        return results</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="convSearchPython.pipelines.AbstractWrapperPipelineInterface" href="index.html#convSearchPython.pipelines.AbstractWrapperPipelineInterface">AbstractWrapperPipelineInterface</a></li>
<li><a title="convSearchPython.pipelines.AbstractPipeline" href="index.html#convSearchPython.pipelines.AbstractPipeline">AbstractPipeline</a></li>
<li><a title="convSearchPython.pipelines.QueriesStructNeedingInterface" href="index.html#convSearchPython.pipelines.QueriesStructNeedingInterface">QueriesStructNeedingInterface</a></li>
<li><a title="convSearchPython.pipelines.CachedPipelineInterface" href="index.html#convSearchPython.pipelines.CachedPipelineInterface">CachedPipelineInterface</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="convSearchPython.pipelines.AbstractWrapperPipelineInterface" href="index.html#convSearchPython.pipelines.AbstractWrapperPipelineInterface">AbstractWrapperPipelineInterface</a></b></code>:
<ul class="hlist">
<li><code><a title="convSearchPython.pipelines.AbstractWrapperPipelineInterface.__call__" href="index.html#convSearchPython.pipelines.AbstractPipeline.__call__">__call__</a></code></li>
<li><code><a title="convSearchPython.pipelines.AbstractWrapperPipelineInterface.name" href="index.html#convSearchPython.pipelines.AbstractPipeline.name">name</a></code></li>
<li><code><a title="convSearchPython.pipelines.AbstractWrapperPipelineInterface.run_on" href="index.html#convSearchPython.pipelines.AbstractPipeline.run_on">run_on</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="convSearchPython.pipelines" href="index.html">convSearchPython.pipelines</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="convSearchPython.pipelines.sub_index.SubIndexPipeline" href="#convSearchPython.pipelines.sub_index.SubIndexPipeline">SubIndexPipeline</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>