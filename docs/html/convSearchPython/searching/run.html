<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>convSearchPython.searching.run API documentation</title>
<meta name="description" content="Representation of a run" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>convSearchPython.searching.run</code></h1>
</header>
<section id="section-intro">
<p>Representation of a run</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Representation of a run&#34;&#34;&#34;
import gc
import gzip
import logging
from datetime import datetime, timedelta
from multiprocessing.pool import Pool
from pathlib import Path
from time import time
from typing import Optional, Tuple, Set, Dict, List

import pandas as pd
from pandas import DataFrame

from convSearchPython.basics import conf
from convSearchPython.pipelines import Pipeline
from convSearchPython.utils import save_results, group_measure, mkdir
from convSearchPython.utils.data_utils import limit_per_query
from convSearchPython.utils.evaluation import evaluate
from convSearchPython.utils.parallel_utils import TimeLogWrapper
from convSearchPython.utils.save_results import save_trec_run

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

pkl_log_warn = False


def get_run_dir(name: Optional[str]) -&gt; str:
    workdir = conf.get(&#39;GENERAL&#39;, &#39;workdir&#39;)
    now = datetime.now().strftime(&#39;%Y_%m_%dT%H_%M_%S&#39;)
    if name is None:
        name = &#39;run&#39;
    return f&#39;{workdir}/{name}_{now}&#39;


class Run:
    def __init__(self, name: str = None, parallel_pool: Pool = None):
        &#34;&#34;&#34;Class that represent a run.

        - name: run name (default None)&#34;&#34;&#34;
        self.__run_name = name
        self.__dir = get_run_dir(name)
        self.__pipelines: List[Tuple[str, Pipeline]] = []
        self.__names: Set[str] = set()
        self.__result: Optional[DataFrame] = None
        self.__parallel_pool = parallel_pool

    @property
    def name(self) -&gt; str:
        return self.__run_name

    @property
    def pipelines_names(self) -&gt; Tuple[str]:
        return tuple(self.__names)

    @property
    def was_executed(self) -&gt; bool:
        return self.__result is not None

    def add(self, pipeline: Pipeline, name: str = None, discard_dup=False) -&gt; &#39;Run&#39;:
        &#34;&#34;&#34;Add the specified pipeline to the run.
        Return itself so calls can be chained.

        :param pipeline: the class of the pipeline
        :param name: if not None, replace the name of the pipeline (must be unique)
        :param discard_dup: if True discard run that are already present instead of
                throwing an exception&#34;&#34;&#34;
        if self.was_executed:
            raise Exception(&#39;cannot add pipeline to an already executed run&#39;)
        if name is None:
            name = pipeline.name
        if name in self.__names:
            if discard_dup:
                logger.warning(&#39;discarded duplicate of run %s&#39;, name)
                return self
            raise Exception(f&#39;name collision: {name}&#39;)
        self.__names.add(name)
        self.__pipelines.append((name, pipeline))
        logger.info(&#39;added pipeline %s to the run&#39;, name)
        return self

    @staticmethod
    def __execute_loop(pipelines: List[Tuple[str, Pipeline]], queries: DataFrame, parallel_pool):
        size = len(pipelines)
        count = 0
        for name, pipeline in pipelines:
            st = time()
            res = pipeline(queries, parallel_pool=parallel_pool)
            res[&#39;name&#39;] = name
            count += 1
            logger.info(f&#39;[%4d/%d] completed search with pipeline %s in %s&#39;,
                        count, size, name, timedelta(seconds=(time() - st)))
            gc.collect()  # may help in some cases
            yield res

    def execute(self, queries: DataFrame, qrels: DataFrame = None, limit=0) -&gt; DataFrame:
        &#34;&#34;&#34;Execute the run and return the result. If qrels is provided the the label column is added to results&#34;&#34;&#34;
        if self.was_executed:
            raise Exception(&#39;cannot re-execute an already executed run&#39;)
        logger.info(&#39;Starting pipelines execution %s&#39;, &#39;in a single process&#39; if self.__parallel_pool is None else
                    &#39;with a parallel pool&#39;)
        logger.info(&#39;%d pipelines to execute&#39;, len(self.__pipelines))
        results = list(self.__execute_loop(self.__pipelines, queries, self.__parallel_pool))
        logger.info(&#39;all pipelines executed, starting result concatenation&#39;)
        st = time()
        self.__result = pd.concat(results)
        logger.info(f&#39;all results concatenated in {timedelta(seconds=(time() - st))}&#39;)
        if qrels is not None:
            try:
                self.__result = self.__result.merge(qrels, how=&#39;left&#39;, on=[&#39;qid&#39;, &#39;docno&#39;])
                logger.info(&#39;Added label to results&#39;)
            except Exception as ex:
                logger.error(&#39;Failed to add labels to results&#39;)
                logger.error(ex, exc_info=True)
        if limit &gt; 0:
            self.__result = limit_per_query(self.__result, limit)
        return self.__result

    @property
    def result(self) -&gt; Optional[DataFrame]:
        return self.__result

    def save_as_trec(self, save_global=False, save_single=True):
        &#34;&#34;&#34;Save run in trec_eval format (gzipped)

        - save_global: save the global result (default false)
        - save_single: save single sub-runs (default true)&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot save a run that was not executed&#39;)
        mkdir(self.__dir)
        futures = []
        if save_global:
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(save_trec_run, &#39;run saved in trec format in %s&#39;, __name__) \
                    .run(self.__parallel_pool, (self.__result, f&#39;{self.__dir}/run.txt.gz&#39;))
                futures.append(f)
            else:
                st = time()
                save_trec_run(self.__result, f&#39;{self.__dir}/run.txt.gz&#39;)
                logger.info(&#39;run saved in trec format in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_single:
            sdir = f&#39;{self.__dir}/sub-runs&#39;
            mkdir(sdir)
            for name, result in self.__result.groupby(&#39;name&#39;):
                if self.__parallel_pool is not None:
                    f = TimeLogWrapper(save_trec_run, f&#39;sub-run {name} saved in trec format in %s&#39;, __name__) \
                        .run(self.__parallel_pool, (result.reset_index(), f&#39;{sdir}/{name}.txt.gz&#39;))
                    futures.append(f)
                else:
                    st = time()
                    save_trec_run(result.reset_index(), f&#39;{sdir}/{name}.txt.gz&#39;)
                    logger.info(&#39;sub-run %s saved in trec format in %s&#39;, name, str(timedelta(seconds=(time() - st))))
        for f in futures:
            f.wait()

    def save_as_csv(self, save_global=False, save_single=True, limit=0):
        &#34;&#34;&#34;Save run in csv format (gzipped)

        - save_global: save the global result (default false)
        - save_single: save single sub-runs (default true)
        - limit: maximum number of result for query to save, 0 for all (default 0)&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot save a run that was not executed&#39;)
        mkdir(self.__dir)
        result = self.__result
        futures = []
        if limit &gt; 0:
            st = time()
            result = limit_per_query(result, limit)
            logger.info(&#39;reduced dataset in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_global:
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(getattr(result, &#39;to_csv&#39;), &#39;run saved as csv in %s&#39;, __name__)\
                    .run(self.__parallel_pool, [f&#39;{self.__dir}/run.csv.gz&#39;], {&#39;index&#39;: False})
                futures.append(f)
            else:
                st = time()
                result.to_csv(f&#39;{self.__dir}/run.csv.gz&#39;, index=False)
                logger.info(&#39;run saved as csv in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_single:
            sdir = f&#39;{self.__dir}/sub-runs&#39;
            mkdir(sdir)
            for name, res in result.groupby(&#39;name&#39;):
                if self.__parallel_pool is not None:
                    f = TimeLogWrapper(getattr(res, &#39;to_csv&#39;), f&#39;sub-run {name} saved as csv in %s&#39;, __name__)\
                        .run(self.__parallel_pool, [f&#39;{sdir}/{name}.csv.gz&#39;], {&#39;index&#39;: False})
                    futures.append(f)
                else:
                    st = time()
                    res.reset_index().to_csv(f&#39;{sdir}/{name}.csv.gz&#39;, index=False)
                    logger.info(&#39;sub-run %s saved as csv in %s&#39;, name, str(timedelta(seconds=(time() - st))))
        for f in futures:
            f.wait()

    def save_as_pkl(self, save_global=False, save_single=True, limit=0):
        &#34;&#34;&#34;Save run in pkl format (gzipped)

        - save_global: save the global result (default false)
        - save_single: save single sub-runs (default true)
        - limit: maximum number of result for query to save, 0 for all (default 0)&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot save a run that was not executed&#39;)
        global pkl_log_warn
        if not pkl_log_warn:
            logger.warning(&#39;Save as pkl: you may need pandas version %s or later to deserialize&#39;, str(pd.__version__))
            pkl_log_warn = True
        mkdir(self.__dir)
        result = self.__result
        futures = []
        if limit &gt; 0:
            st = time()
            result = limit_per_query(result, limit)
            logger.info(&#39;reduced dataset in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_global:
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(getattr(result, &#39;to_pickle&#39;), &#39;run saved as pkl in %s&#39;, __name__)\
                    .run(self.__parallel_pool, [f&#39;{self.__dir}/run.pkl.gz&#39;])
                futures.append(f)
            else:
                st = time()
                result.to_pickle(f&#39;{self.__dir}/run.pkl.gz&#39;)
                logger.info(&#39;run saved as pkl in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_single:
            sdir = f&#39;{self.__dir}/sub-runs&#39;
            mkdir(sdir)
            for name, res in result.groupby(&#39;name&#39;):
                if self.__parallel_pool is not None:
                    f = TimeLogWrapper(getattr(res, &#39;to_pickle&#39;), f&#39;sub-run {name} saved as pkl in %s&#39;, __name__)\
                        .run(self.__parallel_pool, [f&#39;{sdir}/{name}.pkl.gz&#39;])
                    futures.append(f)
                else:
                    st = time()
                    res.reset_index().to_pickle(f&#39;{sdir}/{name}.pkl.gz&#39;)
                    logger.info(&#39;sub-run %s saved as pkl in %s&#39;, name, str(timedelta(seconds=(time() - st))))
        for f in futures:
            f.wait()

    def get_measures(self, metrics: list, qrels: DataFrame, query_map: Dict[str, Tuple[str, int]]) \
            -&gt; Dict[str, &#39;RunMeasure&#39;]:
        &#34;&#34;&#34;Return a dict of RunMeasure objects with measures (all_queries, global_mean, conversation_mean)

        - queries: queries used
        - metrics: list of metrics to compute
        - qrels: qrels DataFrame
        - query_map: query map for the used queries&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot calculate measure for a non executed run&#39;)
        d = {}

        st = time()
        all_queries = evaluate(self.__result, metrics, qrels)
        if &#39;index&#39; in all_queries.columns:
            all_queries.drop(&#39;index&#39;, axis=1, inplace=True)
        d[&#39;all_queries&#39;] = RunMeasure(&#39;all_queries&#39;, all_queries, self.__dir)
        logger.info(f&#39;generated dataset &#34;all_queries&#34; in {timedelta(seconds=(time() - st))}&#39;)

        st = time()
        global_mean = group_measure.name_measure_mean(all_queries)
        d[&#39;global_mean&#39;] = RunMeasure(&#39;global_mean&#39;, global_mean, self.__dir)
        logger.info(f&#39;generated dataset &#34;global_mean&#34; in {timedelta(seconds=(time() - st))}&#39;)

        st = time()
        conversation_mean = group_measure.per_conversation_mean(all_queries, query_map)
        d[&#39;conversation_mean&#39;] = RunMeasure(&#39;conversation_mean&#39;, conversation_mean, self.__dir)
        logger.info(f&#39;generated dataset &#34;conversation_mean&#34; in {timedelta(seconds=(time() - st))}&#39;)

        st = time()
        parsable_group = group_measure.parsable_measures(all_queries, query_map)
        parsable_path = mkdir(Path(self.__dir, &#39;parsable_measures&#39;))
        for k, v in parsable_group.items():
            d[f&#39;parsable_{k}&#39;] = RunMeasure(k, v, parsable_path)
        logger.info(f&#39;generated \&#39;parsable datasets\&#39; in {timedelta(seconds=(time() - st))}&#39;)

        logger.info(&#39;all measures generated&#39;)

        return d


class RunMeasure:
    def __init__(self, name: str, measures: DataFrame, run_dir: str):
        &#34;&#34;&#34;Measure wrapper that provide convenient methods for saving

        - name: name of the measure (ex. mean, conv_mean, all_queries, ...)
        - measures: DataFrame with the measure
        - run_dir: directory of the relative run&#34;&#34;&#34;
        self.__name = name
        self.__measures = measures
        self.__dir = run_dir

    @property
    def name(self) -&gt; str:
        return self.__name

    @property
    def measures(self) -&gt; DataFrame:
        return self.__measures

    def save_simple(self, gz=False):
        &#34;&#34;&#34;Save measure as simple

        - gz: if enable compression (default false)&#34;&#34;&#34;
        mkdir(self.__dir)
        if gz:
            with gzip.open(f&#39;{self.__dir}/{self.name}.txt.gz&#39;, &#39;wt&#39;) as file:
                save_results.save_simple(self.measures, file)
        else:
            save_results.save_simple(self.measures, f&#39;{self.__dir}/{self.name}.txt&#39;)

    def save_as_csv(self, gz=False):
        &#34;&#34;&#34;Save measures as csv

        - gz: if enable compression (default false)&#34;&#34;&#34;
        mkdir(self.__dir)
        ext = &#39;csv.gz&#39; if gz else &#39;csv&#39;
        self.measures.to_csv(f&#39;{self.__dir}/{self.name}.{ext}&#39;, index=False)

    def save_as_pkl(self, gz=True):
        &#34;&#34;&#34;Save measures as pkl

        - gz: if enable compression (default true)&#34;&#34;&#34;
        global pkl_log_warn
        if not pkl_log_warn:
            logger.warning(&#39;Save as pkl: you may need pandas version %s or later to deserialize&#39;, str(pd.__version__))
            pkl_log_warn = True
        mkdir(self.__dir)
        ext = &#39;pkl.gz&#39; if gz else &#39;pkl&#39;
        self.measures.to_pickle(f&#39;{self.__dir}/{self.name}.{ext}&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="convSearchPython.searching.run.get_run_dir"><code class="name flex">
<span>def <span class="ident">get_run_dir</span></span>(<span>name: Optional[str]) ‑> str</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_run_dir(name: Optional[str]) -&gt; str:
    workdir = conf.get(&#39;GENERAL&#39;, &#39;workdir&#39;)
    now = datetime.now().strftime(&#39;%Y_%m_%dT%H_%M_%S&#39;)
    if name is None:
        name = &#39;run&#39;
    return f&#39;{workdir}/{name}_{now}&#39;</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="convSearchPython.searching.run.Run"><code class="flex name class">
<span>class <span class="ident">Run</span></span>
<span>(</span><span>name: str = None, parallel_pool: multiprocessing.pool.Pool = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class that represent a run.</p>
<ul>
<li>name: run name (default None)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Run:
    def __init__(self, name: str = None, parallel_pool: Pool = None):
        &#34;&#34;&#34;Class that represent a run.

        - name: run name (default None)&#34;&#34;&#34;
        self.__run_name = name
        self.__dir = get_run_dir(name)
        self.__pipelines: List[Tuple[str, Pipeline]] = []
        self.__names: Set[str] = set()
        self.__result: Optional[DataFrame] = None
        self.__parallel_pool = parallel_pool

    @property
    def name(self) -&gt; str:
        return self.__run_name

    @property
    def pipelines_names(self) -&gt; Tuple[str]:
        return tuple(self.__names)

    @property
    def was_executed(self) -&gt; bool:
        return self.__result is not None

    def add(self, pipeline: Pipeline, name: str = None, discard_dup=False) -&gt; &#39;Run&#39;:
        &#34;&#34;&#34;Add the specified pipeline to the run.
        Return itself so calls can be chained.

        :param pipeline: the class of the pipeline
        :param name: if not None, replace the name of the pipeline (must be unique)
        :param discard_dup: if True discard run that are already present instead of
                throwing an exception&#34;&#34;&#34;
        if self.was_executed:
            raise Exception(&#39;cannot add pipeline to an already executed run&#39;)
        if name is None:
            name = pipeline.name
        if name in self.__names:
            if discard_dup:
                logger.warning(&#39;discarded duplicate of run %s&#39;, name)
                return self
            raise Exception(f&#39;name collision: {name}&#39;)
        self.__names.add(name)
        self.__pipelines.append((name, pipeline))
        logger.info(&#39;added pipeline %s to the run&#39;, name)
        return self

    @staticmethod
    def __execute_loop(pipelines: List[Tuple[str, Pipeline]], queries: DataFrame, parallel_pool):
        size = len(pipelines)
        count = 0
        for name, pipeline in pipelines:
            st = time()
            res = pipeline(queries, parallel_pool=parallel_pool)
            res[&#39;name&#39;] = name
            count += 1
            logger.info(f&#39;[%4d/%d] completed search with pipeline %s in %s&#39;,
                        count, size, name, timedelta(seconds=(time() - st)))
            gc.collect()  # may help in some cases
            yield res

    def execute(self, queries: DataFrame, qrels: DataFrame = None, limit=0) -&gt; DataFrame:
        &#34;&#34;&#34;Execute the run and return the result. If qrels is provided the the label column is added to results&#34;&#34;&#34;
        if self.was_executed:
            raise Exception(&#39;cannot re-execute an already executed run&#39;)
        logger.info(&#39;Starting pipelines execution %s&#39;, &#39;in a single process&#39; if self.__parallel_pool is None else
                    &#39;with a parallel pool&#39;)
        logger.info(&#39;%d pipelines to execute&#39;, len(self.__pipelines))
        results = list(self.__execute_loop(self.__pipelines, queries, self.__parallel_pool))
        logger.info(&#39;all pipelines executed, starting result concatenation&#39;)
        st = time()
        self.__result = pd.concat(results)
        logger.info(f&#39;all results concatenated in {timedelta(seconds=(time() - st))}&#39;)
        if qrels is not None:
            try:
                self.__result = self.__result.merge(qrels, how=&#39;left&#39;, on=[&#39;qid&#39;, &#39;docno&#39;])
                logger.info(&#39;Added label to results&#39;)
            except Exception as ex:
                logger.error(&#39;Failed to add labels to results&#39;)
                logger.error(ex, exc_info=True)
        if limit &gt; 0:
            self.__result = limit_per_query(self.__result, limit)
        return self.__result

    @property
    def result(self) -&gt; Optional[DataFrame]:
        return self.__result

    def save_as_trec(self, save_global=False, save_single=True):
        &#34;&#34;&#34;Save run in trec_eval format (gzipped)

        - save_global: save the global result (default false)
        - save_single: save single sub-runs (default true)&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot save a run that was not executed&#39;)
        mkdir(self.__dir)
        futures = []
        if save_global:
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(save_trec_run, &#39;run saved in trec format in %s&#39;, __name__) \
                    .run(self.__parallel_pool, (self.__result, f&#39;{self.__dir}/run.txt.gz&#39;))
                futures.append(f)
            else:
                st = time()
                save_trec_run(self.__result, f&#39;{self.__dir}/run.txt.gz&#39;)
                logger.info(&#39;run saved in trec format in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_single:
            sdir = f&#39;{self.__dir}/sub-runs&#39;
            mkdir(sdir)
            for name, result in self.__result.groupby(&#39;name&#39;):
                if self.__parallel_pool is not None:
                    f = TimeLogWrapper(save_trec_run, f&#39;sub-run {name} saved in trec format in %s&#39;, __name__) \
                        .run(self.__parallel_pool, (result.reset_index(), f&#39;{sdir}/{name}.txt.gz&#39;))
                    futures.append(f)
                else:
                    st = time()
                    save_trec_run(result.reset_index(), f&#39;{sdir}/{name}.txt.gz&#39;)
                    logger.info(&#39;sub-run %s saved in trec format in %s&#39;, name, str(timedelta(seconds=(time() - st))))
        for f in futures:
            f.wait()

    def save_as_csv(self, save_global=False, save_single=True, limit=0):
        &#34;&#34;&#34;Save run in csv format (gzipped)

        - save_global: save the global result (default false)
        - save_single: save single sub-runs (default true)
        - limit: maximum number of result for query to save, 0 for all (default 0)&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot save a run that was not executed&#39;)
        mkdir(self.__dir)
        result = self.__result
        futures = []
        if limit &gt; 0:
            st = time()
            result = limit_per_query(result, limit)
            logger.info(&#39;reduced dataset in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_global:
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(getattr(result, &#39;to_csv&#39;), &#39;run saved as csv in %s&#39;, __name__)\
                    .run(self.__parallel_pool, [f&#39;{self.__dir}/run.csv.gz&#39;], {&#39;index&#39;: False})
                futures.append(f)
            else:
                st = time()
                result.to_csv(f&#39;{self.__dir}/run.csv.gz&#39;, index=False)
                logger.info(&#39;run saved as csv in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_single:
            sdir = f&#39;{self.__dir}/sub-runs&#39;
            mkdir(sdir)
            for name, res in result.groupby(&#39;name&#39;):
                if self.__parallel_pool is not None:
                    f = TimeLogWrapper(getattr(res, &#39;to_csv&#39;), f&#39;sub-run {name} saved as csv in %s&#39;, __name__)\
                        .run(self.__parallel_pool, [f&#39;{sdir}/{name}.csv.gz&#39;], {&#39;index&#39;: False})
                    futures.append(f)
                else:
                    st = time()
                    res.reset_index().to_csv(f&#39;{sdir}/{name}.csv.gz&#39;, index=False)
                    logger.info(&#39;sub-run %s saved as csv in %s&#39;, name, str(timedelta(seconds=(time() - st))))
        for f in futures:
            f.wait()

    def save_as_pkl(self, save_global=False, save_single=True, limit=0):
        &#34;&#34;&#34;Save run in pkl format (gzipped)

        - save_global: save the global result (default false)
        - save_single: save single sub-runs (default true)
        - limit: maximum number of result for query to save, 0 for all (default 0)&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot save a run that was not executed&#39;)
        global pkl_log_warn
        if not pkl_log_warn:
            logger.warning(&#39;Save as pkl: you may need pandas version %s or later to deserialize&#39;, str(pd.__version__))
            pkl_log_warn = True
        mkdir(self.__dir)
        result = self.__result
        futures = []
        if limit &gt; 0:
            st = time()
            result = limit_per_query(result, limit)
            logger.info(&#39;reduced dataset in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_global:
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(getattr(result, &#39;to_pickle&#39;), &#39;run saved as pkl in %s&#39;, __name__)\
                    .run(self.__parallel_pool, [f&#39;{self.__dir}/run.pkl.gz&#39;])
                futures.append(f)
            else:
                st = time()
                result.to_pickle(f&#39;{self.__dir}/run.pkl.gz&#39;)
                logger.info(&#39;run saved as pkl in %s&#39;, str(timedelta(seconds=(time() - st))))
        if save_single:
            sdir = f&#39;{self.__dir}/sub-runs&#39;
            mkdir(sdir)
            for name, res in result.groupby(&#39;name&#39;):
                if self.__parallel_pool is not None:
                    f = TimeLogWrapper(getattr(res, &#39;to_pickle&#39;), f&#39;sub-run {name} saved as pkl in %s&#39;, __name__)\
                        .run(self.__parallel_pool, [f&#39;{sdir}/{name}.pkl.gz&#39;])
                    futures.append(f)
                else:
                    st = time()
                    res.reset_index().to_pickle(f&#39;{sdir}/{name}.pkl.gz&#39;)
                    logger.info(&#39;sub-run %s saved as pkl in %s&#39;, name, str(timedelta(seconds=(time() - st))))
        for f in futures:
            f.wait()

    def get_measures(self, metrics: list, qrels: DataFrame, query_map: Dict[str, Tuple[str, int]]) \
            -&gt; Dict[str, &#39;RunMeasure&#39;]:
        &#34;&#34;&#34;Return a dict of RunMeasure objects with measures (all_queries, global_mean, conversation_mean)

        - queries: queries used
        - metrics: list of metrics to compute
        - qrels: qrels DataFrame
        - query_map: query map for the used queries&#34;&#34;&#34;
        if not self.was_executed:
            raise Exception(&#39;cannot calculate measure for a non executed run&#39;)
        d = {}

        st = time()
        all_queries = evaluate(self.__result, metrics, qrels)
        if &#39;index&#39; in all_queries.columns:
            all_queries.drop(&#39;index&#39;, axis=1, inplace=True)
        d[&#39;all_queries&#39;] = RunMeasure(&#39;all_queries&#39;, all_queries, self.__dir)
        logger.info(f&#39;generated dataset &#34;all_queries&#34; in {timedelta(seconds=(time() - st))}&#39;)

        st = time()
        global_mean = group_measure.name_measure_mean(all_queries)
        d[&#39;global_mean&#39;] = RunMeasure(&#39;global_mean&#39;, global_mean, self.__dir)
        logger.info(f&#39;generated dataset &#34;global_mean&#34; in {timedelta(seconds=(time() - st))}&#39;)

        st = time()
        conversation_mean = group_measure.per_conversation_mean(all_queries, query_map)
        d[&#39;conversation_mean&#39;] = RunMeasure(&#39;conversation_mean&#39;, conversation_mean, self.__dir)
        logger.info(f&#39;generated dataset &#34;conversation_mean&#34; in {timedelta(seconds=(time() - st))}&#39;)

        st = time()
        parsable_group = group_measure.parsable_measures(all_queries, query_map)
        parsable_path = mkdir(Path(self.__dir, &#39;parsable_measures&#39;))
        for k, v in parsable_group.items():
            d[f&#39;parsable_{k}&#39;] = RunMeasure(k, v, parsable_path)
        logger.info(f&#39;generated \&#39;parsable datasets\&#39; in {timedelta(seconds=(time() - st))}&#39;)

        logger.info(&#39;all measures generated&#39;)

        return d</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="convSearchPython.searching.run.Run.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def name(self) -&gt; str:
    return self.__run_name</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.pipelines_names"><code class="name">var <span class="ident">pipelines_names</span> : Tuple[str]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def pipelines_names(self) -&gt; Tuple[str]:
    return tuple(self.__names)</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.was_executed"><code class="name">var <span class="ident">was_executed</span> : bool</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def was_executed(self) -&gt; bool:
    return self.__result is not None</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.result"><code class="name">var <span class="ident">result</span> : Optional[pandas.core.frame.DataFrame]</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def result(self) -&gt; Optional[DataFrame]:
    return self.__result</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="convSearchPython.searching.run.Run.add"><code class="name flex">
<span>def <span class="ident">add</span></span>(<span>self, pipeline: <a title="convSearchPython.pipelines.Pipeline" href="../pipelines/index.html#convSearchPython.pipelines.Pipeline">Pipeline</a>, name: str = None, discard_dup=False) ‑> <a title="convSearchPython.searching.run.Run" href="#convSearchPython.searching.run.Run">Run</a></span>
</code></dt>
<dd>
<div class="desc"><p>Add the specified pipeline to the run.
Return itself so calls can be chained.</p>
<p>:param pipeline: the class of the pipeline
:param name: if not None, replace the name of the pipeline (must be unique)
:param discard_dup: if True discard run that are already present instead of
throwing an exception</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add(self, pipeline: Pipeline, name: str = None, discard_dup=False) -&gt; &#39;Run&#39;:
    &#34;&#34;&#34;Add the specified pipeline to the run.
    Return itself so calls can be chained.

    :param pipeline: the class of the pipeline
    :param name: if not None, replace the name of the pipeline (must be unique)
    :param discard_dup: if True discard run that are already present instead of
            throwing an exception&#34;&#34;&#34;
    if self.was_executed:
        raise Exception(&#39;cannot add pipeline to an already executed run&#39;)
    if name is None:
        name = pipeline.name
    if name in self.__names:
        if discard_dup:
            logger.warning(&#39;discarded duplicate of run %s&#39;, name)
            return self
        raise Exception(f&#39;name collision: {name}&#39;)
    self.__names.add(name)
    self.__pipelines.append((name, pipeline))
    logger.info(&#39;added pipeline %s to the run&#39;, name)
    return self</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.execute"><code class="name flex">
<span>def <span class="ident">execute</span></span>(<span>self, queries: pandas.core.frame.DataFrame, qrels: pandas.core.frame.DataFrame = None, limit=0) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Execute the run and return the result. If qrels is provided the the label column is added to results</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute(self, queries: DataFrame, qrels: DataFrame = None, limit=0) -&gt; DataFrame:
    &#34;&#34;&#34;Execute the run and return the result. If qrels is provided the the label column is added to results&#34;&#34;&#34;
    if self.was_executed:
        raise Exception(&#39;cannot re-execute an already executed run&#39;)
    logger.info(&#39;Starting pipelines execution %s&#39;, &#39;in a single process&#39; if self.__parallel_pool is None else
                &#39;with a parallel pool&#39;)
    logger.info(&#39;%d pipelines to execute&#39;, len(self.__pipelines))
    results = list(self.__execute_loop(self.__pipelines, queries, self.__parallel_pool))
    logger.info(&#39;all pipelines executed, starting result concatenation&#39;)
    st = time()
    self.__result = pd.concat(results)
    logger.info(f&#39;all results concatenated in {timedelta(seconds=(time() - st))}&#39;)
    if qrels is not None:
        try:
            self.__result = self.__result.merge(qrels, how=&#39;left&#39;, on=[&#39;qid&#39;, &#39;docno&#39;])
            logger.info(&#39;Added label to results&#39;)
        except Exception as ex:
            logger.error(&#39;Failed to add labels to results&#39;)
            logger.error(ex, exc_info=True)
    if limit &gt; 0:
        self.__result = limit_per_query(self.__result, limit)
    return self.__result</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.save_as_trec"><code class="name flex">
<span>def <span class="ident">save_as_trec</span></span>(<span>self, save_global=False, save_single=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Save run in trec_eval format (gzipped)</p>
<ul>
<li>save_global: save the global result (default false)</li>
<li>save_single: save single sub-runs (default true)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_as_trec(self, save_global=False, save_single=True):
    &#34;&#34;&#34;Save run in trec_eval format (gzipped)

    - save_global: save the global result (default false)
    - save_single: save single sub-runs (default true)&#34;&#34;&#34;
    if not self.was_executed:
        raise Exception(&#39;cannot save a run that was not executed&#39;)
    mkdir(self.__dir)
    futures = []
    if save_global:
        if self.__parallel_pool is not None:
            f = TimeLogWrapper(save_trec_run, &#39;run saved in trec format in %s&#39;, __name__) \
                .run(self.__parallel_pool, (self.__result, f&#39;{self.__dir}/run.txt.gz&#39;))
            futures.append(f)
        else:
            st = time()
            save_trec_run(self.__result, f&#39;{self.__dir}/run.txt.gz&#39;)
            logger.info(&#39;run saved in trec format in %s&#39;, str(timedelta(seconds=(time() - st))))
    if save_single:
        sdir = f&#39;{self.__dir}/sub-runs&#39;
        mkdir(sdir)
        for name, result in self.__result.groupby(&#39;name&#39;):
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(save_trec_run, f&#39;sub-run {name} saved in trec format in %s&#39;, __name__) \
                    .run(self.__parallel_pool, (result.reset_index(), f&#39;{sdir}/{name}.txt.gz&#39;))
                futures.append(f)
            else:
                st = time()
                save_trec_run(result.reset_index(), f&#39;{sdir}/{name}.txt.gz&#39;)
                logger.info(&#39;sub-run %s saved in trec format in %s&#39;, name, str(timedelta(seconds=(time() - st))))
    for f in futures:
        f.wait()</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.save_as_csv"><code class="name flex">
<span>def <span class="ident">save_as_csv</span></span>(<span>self, save_global=False, save_single=True, limit=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Save run in csv format (gzipped)</p>
<ul>
<li>save_global: save the global result (default false)</li>
<li>save_single: save single sub-runs (default true)</li>
<li>limit: maximum number of result for query to save, 0 for all (default 0)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_as_csv(self, save_global=False, save_single=True, limit=0):
    &#34;&#34;&#34;Save run in csv format (gzipped)

    - save_global: save the global result (default false)
    - save_single: save single sub-runs (default true)
    - limit: maximum number of result for query to save, 0 for all (default 0)&#34;&#34;&#34;
    if not self.was_executed:
        raise Exception(&#39;cannot save a run that was not executed&#39;)
    mkdir(self.__dir)
    result = self.__result
    futures = []
    if limit &gt; 0:
        st = time()
        result = limit_per_query(result, limit)
        logger.info(&#39;reduced dataset in %s&#39;, str(timedelta(seconds=(time() - st))))
    if save_global:
        if self.__parallel_pool is not None:
            f = TimeLogWrapper(getattr(result, &#39;to_csv&#39;), &#39;run saved as csv in %s&#39;, __name__)\
                .run(self.__parallel_pool, [f&#39;{self.__dir}/run.csv.gz&#39;], {&#39;index&#39;: False})
            futures.append(f)
        else:
            st = time()
            result.to_csv(f&#39;{self.__dir}/run.csv.gz&#39;, index=False)
            logger.info(&#39;run saved as csv in %s&#39;, str(timedelta(seconds=(time() - st))))
    if save_single:
        sdir = f&#39;{self.__dir}/sub-runs&#39;
        mkdir(sdir)
        for name, res in result.groupby(&#39;name&#39;):
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(getattr(res, &#39;to_csv&#39;), f&#39;sub-run {name} saved as csv in %s&#39;, __name__)\
                    .run(self.__parallel_pool, [f&#39;{sdir}/{name}.csv.gz&#39;], {&#39;index&#39;: False})
                futures.append(f)
            else:
                st = time()
                res.reset_index().to_csv(f&#39;{sdir}/{name}.csv.gz&#39;, index=False)
                logger.info(&#39;sub-run %s saved as csv in %s&#39;, name, str(timedelta(seconds=(time() - st))))
    for f in futures:
        f.wait()</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.save_as_pkl"><code class="name flex">
<span>def <span class="ident">save_as_pkl</span></span>(<span>self, save_global=False, save_single=True, limit=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Save run in pkl format (gzipped)</p>
<ul>
<li>save_global: save the global result (default false)</li>
<li>save_single: save single sub-runs (default true)</li>
<li>limit: maximum number of result for query to save, 0 for all (default 0)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_as_pkl(self, save_global=False, save_single=True, limit=0):
    &#34;&#34;&#34;Save run in pkl format (gzipped)

    - save_global: save the global result (default false)
    - save_single: save single sub-runs (default true)
    - limit: maximum number of result for query to save, 0 for all (default 0)&#34;&#34;&#34;
    if not self.was_executed:
        raise Exception(&#39;cannot save a run that was not executed&#39;)
    global pkl_log_warn
    if not pkl_log_warn:
        logger.warning(&#39;Save as pkl: you may need pandas version %s or later to deserialize&#39;, str(pd.__version__))
        pkl_log_warn = True
    mkdir(self.__dir)
    result = self.__result
    futures = []
    if limit &gt; 0:
        st = time()
        result = limit_per_query(result, limit)
        logger.info(&#39;reduced dataset in %s&#39;, str(timedelta(seconds=(time() - st))))
    if save_global:
        if self.__parallel_pool is not None:
            f = TimeLogWrapper(getattr(result, &#39;to_pickle&#39;), &#39;run saved as pkl in %s&#39;, __name__)\
                .run(self.__parallel_pool, [f&#39;{self.__dir}/run.pkl.gz&#39;])
            futures.append(f)
        else:
            st = time()
            result.to_pickle(f&#39;{self.__dir}/run.pkl.gz&#39;)
            logger.info(&#39;run saved as pkl in %s&#39;, str(timedelta(seconds=(time() - st))))
    if save_single:
        sdir = f&#39;{self.__dir}/sub-runs&#39;
        mkdir(sdir)
        for name, res in result.groupby(&#39;name&#39;):
            if self.__parallel_pool is not None:
                f = TimeLogWrapper(getattr(res, &#39;to_pickle&#39;), f&#39;sub-run {name} saved as pkl in %s&#39;, __name__)\
                    .run(self.__parallel_pool, [f&#39;{sdir}/{name}.pkl.gz&#39;])
                futures.append(f)
            else:
                st = time()
                res.reset_index().to_pickle(f&#39;{sdir}/{name}.pkl.gz&#39;)
                logger.info(&#39;sub-run %s saved as pkl in %s&#39;, name, str(timedelta(seconds=(time() - st))))
    for f in futures:
        f.wait()</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.Run.get_measures"><code class="name flex">
<span>def <span class="ident">get_measures</span></span>(<span>self, metrics: list, qrels: pandas.core.frame.DataFrame, query_map: Dict[str, Tuple[str, int]]) ‑> Dict[str, <a title="convSearchPython.searching.run.RunMeasure" href="#convSearchPython.searching.run.RunMeasure">RunMeasure</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Return a dict of RunMeasure objects with measures (all_queries, global_mean, conversation_mean)</p>
<ul>
<li>queries: queries used</li>
<li>metrics: list of metrics to compute</li>
<li>qrels: qrels DataFrame</li>
<li>query_map: query map for the used queries</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_measures(self, metrics: list, qrels: DataFrame, query_map: Dict[str, Tuple[str, int]]) \
        -&gt; Dict[str, &#39;RunMeasure&#39;]:
    &#34;&#34;&#34;Return a dict of RunMeasure objects with measures (all_queries, global_mean, conversation_mean)

    - queries: queries used
    - metrics: list of metrics to compute
    - qrels: qrels DataFrame
    - query_map: query map for the used queries&#34;&#34;&#34;
    if not self.was_executed:
        raise Exception(&#39;cannot calculate measure for a non executed run&#39;)
    d = {}

    st = time()
    all_queries = evaluate(self.__result, metrics, qrels)
    if &#39;index&#39; in all_queries.columns:
        all_queries.drop(&#39;index&#39;, axis=1, inplace=True)
    d[&#39;all_queries&#39;] = RunMeasure(&#39;all_queries&#39;, all_queries, self.__dir)
    logger.info(f&#39;generated dataset &#34;all_queries&#34; in {timedelta(seconds=(time() - st))}&#39;)

    st = time()
    global_mean = group_measure.name_measure_mean(all_queries)
    d[&#39;global_mean&#39;] = RunMeasure(&#39;global_mean&#39;, global_mean, self.__dir)
    logger.info(f&#39;generated dataset &#34;global_mean&#34; in {timedelta(seconds=(time() - st))}&#39;)

    st = time()
    conversation_mean = group_measure.per_conversation_mean(all_queries, query_map)
    d[&#39;conversation_mean&#39;] = RunMeasure(&#39;conversation_mean&#39;, conversation_mean, self.__dir)
    logger.info(f&#39;generated dataset &#34;conversation_mean&#34; in {timedelta(seconds=(time() - st))}&#39;)

    st = time()
    parsable_group = group_measure.parsable_measures(all_queries, query_map)
    parsable_path = mkdir(Path(self.__dir, &#39;parsable_measures&#39;))
    for k, v in parsable_group.items():
        d[f&#39;parsable_{k}&#39;] = RunMeasure(k, v, parsable_path)
    logger.info(f&#39;generated \&#39;parsable datasets\&#39; in {timedelta(seconds=(time() - st))}&#39;)

    logger.info(&#39;all measures generated&#39;)

    return d</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="convSearchPython.searching.run.RunMeasure"><code class="flex name class">
<span>class <span class="ident">RunMeasure</span></span>
<span>(</span><span>name: str, measures: pandas.core.frame.DataFrame, run_dir: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Measure wrapper that provide convenient methods for saving</p>
<ul>
<li>name: name of the measure (ex. mean, conv_mean, all_queries, &hellip;)</li>
<li>measures: DataFrame with the measure</li>
<li>run_dir: directory of the relative run</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RunMeasure:
    def __init__(self, name: str, measures: DataFrame, run_dir: str):
        &#34;&#34;&#34;Measure wrapper that provide convenient methods for saving

        - name: name of the measure (ex. mean, conv_mean, all_queries, ...)
        - measures: DataFrame with the measure
        - run_dir: directory of the relative run&#34;&#34;&#34;
        self.__name = name
        self.__measures = measures
        self.__dir = run_dir

    @property
    def name(self) -&gt; str:
        return self.__name

    @property
    def measures(self) -&gt; DataFrame:
        return self.__measures

    def save_simple(self, gz=False):
        &#34;&#34;&#34;Save measure as simple

        - gz: if enable compression (default false)&#34;&#34;&#34;
        mkdir(self.__dir)
        if gz:
            with gzip.open(f&#39;{self.__dir}/{self.name}.txt.gz&#39;, &#39;wt&#39;) as file:
                save_results.save_simple(self.measures, file)
        else:
            save_results.save_simple(self.measures, f&#39;{self.__dir}/{self.name}.txt&#39;)

    def save_as_csv(self, gz=False):
        &#34;&#34;&#34;Save measures as csv

        - gz: if enable compression (default false)&#34;&#34;&#34;
        mkdir(self.__dir)
        ext = &#39;csv.gz&#39; if gz else &#39;csv&#39;
        self.measures.to_csv(f&#39;{self.__dir}/{self.name}.{ext}&#39;, index=False)

    def save_as_pkl(self, gz=True):
        &#34;&#34;&#34;Save measures as pkl

        - gz: if enable compression (default true)&#34;&#34;&#34;
        global pkl_log_warn
        if not pkl_log_warn:
            logger.warning(&#39;Save as pkl: you may need pandas version %s or later to deserialize&#39;, str(pd.__version__))
            pkl_log_warn = True
        mkdir(self.__dir)
        ext = &#39;pkl.gz&#39; if gz else &#39;pkl&#39;
        self.measures.to_pickle(f&#39;{self.__dir}/{self.name}.{ext}&#39;)</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="convSearchPython.searching.run.RunMeasure.name"><code class="name">var <span class="ident">name</span> : str</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def name(self) -&gt; str:
    return self.__name</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.RunMeasure.measures"><code class="name">var <span class="ident">measures</span> : pandas.core.frame.DataFrame</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def measures(self) -&gt; DataFrame:
    return self.__measures</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="convSearchPython.searching.run.RunMeasure.save_simple"><code class="name flex">
<span>def <span class="ident">save_simple</span></span>(<span>self, gz=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Save measure as simple</p>
<ul>
<li>gz: if enable compression (default false)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_simple(self, gz=False):
    &#34;&#34;&#34;Save measure as simple

    - gz: if enable compression (default false)&#34;&#34;&#34;
    mkdir(self.__dir)
    if gz:
        with gzip.open(f&#39;{self.__dir}/{self.name}.txt.gz&#39;, &#39;wt&#39;) as file:
            save_results.save_simple(self.measures, file)
    else:
        save_results.save_simple(self.measures, f&#39;{self.__dir}/{self.name}.txt&#39;)</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.RunMeasure.save_as_csv"><code class="name flex">
<span>def <span class="ident">save_as_csv</span></span>(<span>self, gz=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Save measures as csv</p>
<ul>
<li>gz: if enable compression (default false)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_as_csv(self, gz=False):
    &#34;&#34;&#34;Save measures as csv

    - gz: if enable compression (default false)&#34;&#34;&#34;
    mkdir(self.__dir)
    ext = &#39;csv.gz&#39; if gz else &#39;csv&#39;
    self.measures.to_csv(f&#39;{self.__dir}/{self.name}.{ext}&#39;, index=False)</code></pre>
</details>
</dd>
<dt id="convSearchPython.searching.run.RunMeasure.save_as_pkl"><code class="name flex">
<span>def <span class="ident">save_as_pkl</span></span>(<span>self, gz=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Save measures as pkl</p>
<ul>
<li>gz: if enable compression (default true)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_as_pkl(self, gz=True):
    &#34;&#34;&#34;Save measures as pkl

    - gz: if enable compression (default true)&#34;&#34;&#34;
    global pkl_log_warn
    if not pkl_log_warn:
        logger.warning(&#39;Save as pkl: you may need pandas version %s or later to deserialize&#39;, str(pd.__version__))
        pkl_log_warn = True
    mkdir(self.__dir)
    ext = &#39;pkl.gz&#39; if gz else &#39;pkl&#39;
    self.measures.to_pickle(f&#39;{self.__dir}/{self.name}.{ext}&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="convSearchPython.searching" href="index.html">convSearchPython.searching</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="convSearchPython.searching.run.get_run_dir" href="#convSearchPython.searching.run.get_run_dir">get_run_dir</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="convSearchPython.searching.run.Run" href="#convSearchPython.searching.run.Run">Run</a></code></h4>
<ul class="two-column">
<li><code><a title="convSearchPython.searching.run.Run.add" href="#convSearchPython.searching.run.Run.add">add</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.execute" href="#convSearchPython.searching.run.Run.execute">execute</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.save_as_trec" href="#convSearchPython.searching.run.Run.save_as_trec">save_as_trec</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.save_as_csv" href="#convSearchPython.searching.run.Run.save_as_csv">save_as_csv</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.save_as_pkl" href="#convSearchPython.searching.run.Run.save_as_pkl">save_as_pkl</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.get_measures" href="#convSearchPython.searching.run.Run.get_measures">get_measures</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.name" href="#convSearchPython.searching.run.Run.name">name</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.pipelines_names" href="#convSearchPython.searching.run.Run.pipelines_names">pipelines_names</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.was_executed" href="#convSearchPython.searching.run.Run.was_executed">was_executed</a></code></li>
<li><code><a title="convSearchPython.searching.run.Run.result" href="#convSearchPython.searching.run.Run.result">result</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="convSearchPython.searching.run.RunMeasure" href="#convSearchPython.searching.run.RunMeasure">RunMeasure</a></code></h4>
<ul class="">
<li><code><a title="convSearchPython.searching.run.RunMeasure.save_simple" href="#convSearchPython.searching.run.RunMeasure.save_simple">save_simple</a></code></li>
<li><code><a title="convSearchPython.searching.run.RunMeasure.save_as_csv" href="#convSearchPython.searching.run.RunMeasure.save_as_csv">save_as_csv</a></code></li>
<li><code><a title="convSearchPython.searching.run.RunMeasure.save_as_pkl" href="#convSearchPython.searching.run.RunMeasure.save_as_pkl">save_as_pkl</a></code></li>
<li><code><a title="convSearchPython.searching.run.RunMeasure.name" href="#convSearchPython.searching.run.RunMeasure.name">name</a></code></li>
<li><code><a title="convSearchPython.searching.run.RunMeasure.measures" href="#convSearchPython.searching.run.RunMeasure.measures">measures</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>